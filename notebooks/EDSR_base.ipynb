{"cells":[{"cell_type":"code","metadata":{"deepnote_cell_type":"code","cell_id":"00000-66052f4e-055d-4656-bebc-5e817b550119","output_cleared":false,"source_hash":"21397a4a","execution_start":1606493385576,"execution_millis":1638},"source":"# get root\nimport sys\nsys.path.append(\"../\")\n\n%matplotlib inline\nimport matplotlib.pyplot as plt\nimport matplotlib.patches as mpatches\nimport numpy as np\nimport torch\nimport skimage.io as io\n\nimport model.edsr as edsr\nimport torch.nn.functional as F\n\nfrom skimage.io import imread, imshow\nfrom skimage.transform import rescale, resize, downscale_local_mean\nfrom skimage.filters import gaussian\nfrom skimage import data, color\n\n# options for EDSR\nclass Opt:\n    scale = 4\n    num_blocks = 32\n    num_channels = 256\n    res_scale = 0.1\n\ndef im2tensor(im):\n    np_t = np.ascontiguousarray(im.transpose((2, 0, 1)))\n    tensor = torch.from_numpy(np_t).float()\n    return tensor\n\ndef tensor2im(tensor):\n    tensor = tensor.detach().squeeze(0)\n    im = tensor.clamp(0, 255).round().cpu().byte().permute(1, 2, 0).numpy()\n    return im\n\ndef downsample_img(img, factor=2):\n    downsampled = resize(img, (img.shape[0] // factor, img.shape[1] // factor), order=1, mode='reflect', \n                             clip=True, preserve_range=True, anti_aliasing=True)\n    upsampled = resize(downsampled, img.shape, order=0, mode='reflect', \n                             clip=True, preserve_range=True, anti_aliasing=False)\n    return upsampled / 255\n\nopt = Opt()\ndev = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n\nnet_base = edsr.Net(opt).to(dev)\nnet_moa = edsr.Net(opt).to(dev)\n\nimage_scaling = 8\nimage_name = \"Galah-cockatoo.jpg\"# \"Canon_003_HR.png\"\n\nprint(\"Setup Complete!\")\n ","execution_count":1,"outputs":[{"name":"stderr","text":"/opt/venv/lib/python3.7/site-packages/torch/cuda/__init__.py:52: UserWarning: CUDA initialization: Found no NVIDIA driver on your system. Please check that you have an NVIDIA GPU and installed a driver from http://www.nvidia.com/Download/index.aspx (Triggered internally at  /pytorch/c10/cuda/CUDAFunctions.cpp:100.)\n  return torch._C._cuda_getDeviceCount() > 0\nSetup Complete!\n","output_type":"stream"}]},{"cell_type":"markdown","source":"## DIV2K pre-trained model","metadata":{"deepnote_cell_type":"markdown","cell_id":"00001-484536d0-594a-4e3b-a50e-16a63a128d75","output_cleared":false}},{"cell_type":"code","metadata":{"deepnote_cell_type":"code","cell_id":"00002-338fa5cf-00ae-4bbc-a422-c27b128bdfb2","output_cleared":false,"source_hash":"ec3b60ee","execution_start":1606493387218,"execution_millis":153},"source":"path_image_HR = image_name\n#path_image_LR = \"Canon_003_LR4.png\"\npath_base = \"/data/pt_models/DIV2K_EDSR_X4_base.pt\"\npath_moa = \"/data/pt_models/DIV2K_EDSR_X4_moa.pt\"\n\nstate_base = torch.load(path_base, map_location=lambda storage, loc: storage)\nstate_moa = torch.load(path_moa, map_location=lambda storage, loc: storage)\nnet_base.load_state_dict(state_base)\nnet_moa.load_state_dict(state_moa)\n\nHR = io.imread(path_image_HR)\nHR_tensor = im2tensor(HR).unsqueeze(0).to(dev)\n\n# LR = io.imread(path_image_LR)\nLR = downsample_img(HR, factor=image_scaling)\nLR_tensor = (im2tensor(LR)*255).unsqueeze(0).to(dev)\n\n# apply CutBlur\nLR_tensor[..., 200:600, 200:600] = HR_tensor[..., 200:600, 200:600]\n\nwith torch.no_grad():\n    SR_base = tensor2im(net_base(LR_tensor))\n    SR_moa = tensor2im(net_moa(LR_tensor))","execution_count":2,"outputs":[{"output_type":"error","ename":"FileNotFoundError","evalue":"[Errno 2] No such file or directory: '/data/pt_models/DIV2K_EDSR_X4_base.pt'","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-2-2360a460d1f9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mpath_moa\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"/data/pt_models/DIV2K_EDSR_X4_moa.pt\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mstate_base\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath_base\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmap_location\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mstorage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloc\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstorage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0mstate_moa\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath_moa\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmap_location\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mstorage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloc\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstorage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mnet_base\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_state_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate_base\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/venv/lib/python3.7/site-packages/torch/serialization.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(f, map_location, pickle_module, **pickle_load_args)\u001b[0m\n\u001b[1;32m    579\u001b[0m         \u001b[0mpickle_load_args\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'encoding'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'utf-8'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    580\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 581\u001b[0;31m     \u001b[0;32mwith\u001b[0m \u001b[0m_open_file_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mopened_file\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    582\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0m_is_zipfile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopened_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    583\u001b[0m             \u001b[0;31m# The zipfile reader is going to advance the current file position.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/venv/lib/python3.7/site-packages/torch/serialization.py\u001b[0m in \u001b[0;36m_open_file_like\u001b[0;34m(name_or_buffer, mode)\u001b[0m\n\u001b[1;32m    228\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_open_file_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    229\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0m_is_path\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname_or_buffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 230\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_open_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    231\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    232\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;34m'w'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/venv/lib/python3.7/site-packages/torch/serialization.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, name, mode)\u001b[0m\n\u001b[1;32m    209\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0m_open_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_opener\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    210\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 211\u001b[0;31m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_open_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    212\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    213\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__exit__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/data/pt_models/DIV2K_EDSR_X4_base.pt'"]}]},{"cell_type":"code","metadata":{"deepnote_cell_type":"code","cell_id":"00003-fb9ee0e4-0950-437b-a95a-7ae0b261f8db","output_cleared":false,"source_hash":"7e39af78"},"source":"LR_plot = tensor2im(LR_tensor)[:,:]/255\nHR_plot = HR[:,:] / 255\nSR_base_plot = SR_base[:,:] / 255\nSR_moa_plot = SR_moa[:,:] / 255\n\ndiff_SR_base = (HR_plot-SR_base_plot).mean(2) * 10\ndiff_SR_moa = (HR_plot-SR_moa_plot).mean(2) * 10\n\nf, axarr = plt.subplots(3, 2, figsize=(18, 24))\naxarr[0, 0].imshow(LR_plot)\naxarr[0, 0].set_title(\"Input (Cutblurred LR)\", fontsize=18)\naxarr[0, 0].axis(\"off\")\n \naxarr[0, 1].axis(\"off\")\n \naxarr[1, 0].imshow(SR_base_plot)\naxarr[1, 0].set_title(\"EDSR w/o MoA\", fontsize=18)\naxarr[1, 0].axis(\"off\")\n \naxarr[1, 1].imshow(diff_SR_base, vmin=0, vmax=1, cmap=\"viridis\")\naxarr[1, 1].set_title(\"EDSR w/o MoA (Δ)\", fontsize=18)\naxarr[1, 1].axis(\"off\")\n\naxarr[2, 0].imshow(SR_moa_plot)\naxarr[2, 0].set_title(\"EDSR w/ MoA\", fontsize=18)\naxarr[2, 0].axis(\"off\")\n \naxarr[2, 1].imshow(diff_SR_moa, vmin=0, vmax=1, cmap=\"viridis\")\naxarr[2, 1].set_title(\"EDSR w/ MoA (Δ)\", fontsize=18)\naxarr[2, 1].axis(\"off\")\n\nplt.show()","execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## RealSR pre-trained model","metadata":{"deepnote_cell_type":"markdown","cell_id":"00004-b98bbafa-4913-4092-802f-910db02222e1","output_cleared":false}},{"cell_type":"code","metadata":{"deepnote_cell_type":"code","cell_id":"00005-4b4ed514-4074-44fd-96fd-29f671ef719c","output_cleared":false,"source_hash":"183753f5"},"source":"path_image_HR = image_name\n#path_image_LR = \"Canon_003_LR4.png\"\npath_base = \"/data/pt_models/RealSR_EDSR_X4_base.pt\"\npath_moa = \"/data/pt_models/RealSR_EDSR_X4_moa.pt\"\n\nstate_base = torch.load(path_base, map_location=lambda storage, loc: storage)\nstate_moa = torch.load(path_moa, map_location=lambda storage, loc: storage)\nnet_base.load_state_dict(state_base)\nnet_moa.load_state_dict(state_moa)\n\nHR = io.imread(path_image_HR)\nHR_tensor = im2tensor(HR).unsqueeze(0).to(dev)\n\n# LR = io.imread(path_image_LR)\nLR = downsample_img(HR, factor=image_scaling)\nLR_tensor = (im2tensor(LR)*255).unsqueeze(0).to(dev)\n\n# apply CutBlur\nLR_tensor[..., 200:600, 200:600] = HR_tensor[..., 200:600, 200:600]\n\nwith torch.no_grad():\n    SR_base = tensor2im(net_base(LR_tensor))\n    SR_moa = tensor2im(net_moa(LR_tensor))","execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"deepnote_cell_type":"code","cell_id":"00006-25ded78b-8416-40c4-837c-65981a8fa4c6","output_cleared":false,"source_hash":"7e39af78"},"source":"LR_plot = tensor2im(LR_tensor)[:,:]/255\nHR_plot = HR[:,:] / 255\nSR_base_plot = SR_base[:,:] / 255\nSR_moa_plot = SR_moa[:,:] / 255\n\ndiff_SR_base = (HR_plot-SR_base_plot).mean(2) * 10\ndiff_SR_moa = (HR_plot-SR_moa_plot).mean(2) * 10\n\nf, axarr = plt.subplots(3, 2, figsize=(18, 24))\naxarr[0, 0].imshow(LR_plot)\naxarr[0, 0].set_title(\"Input (Cutblurred LR)\", fontsize=18)\naxarr[0, 0].axis(\"off\")\n \naxarr[0, 1].axis(\"off\")\n \naxarr[1, 0].imshow(SR_base_plot)\naxarr[1, 0].set_title(\"EDSR w/o MoA\", fontsize=18)\naxarr[1, 0].axis(\"off\")\n \naxarr[1, 1].imshow(diff_SR_base, vmin=0, vmax=1, cmap=\"viridis\")\naxarr[1, 1].set_title(\"EDSR w/o MoA (Δ)\", fontsize=18)\naxarr[1, 1].axis(\"off\")\n\naxarr[2, 0].imshow(SR_moa_plot)\naxarr[2, 0].set_title(\"EDSR w/ MoA\", fontsize=18)\naxarr[2, 0].axis(\"off\")\n \naxarr[2, 1].imshow(diff_SR_moa, vmin=0, vmax=1, cmap=\"viridis\")\naxarr[2, 1].set_title(\"EDSR w/ MoA (Δ)\", fontsize=18)\naxarr[2, 1].axis(\"off\")\n\nplt.show()","execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"deepnote_cell_type":"code","cell_id":"00007-2df5d3e2-0ede-44c6-b633-88622bb69138","output_cleared":false,"source_hash":"b623e53d"},"source":"","execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"deepnote_cell_type":"code","cell_id":"00008-d3a7f953-4578-4bec-9606-1026a217f4d6","output_cleared":false,"source_hash":"b623e53d"},"source":"","execution_count":null,"outputs":[]}],"nbformat":4,"nbformat_minor":4,"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.3"},"deepnote_notebook_id":"66b15112-6f7d-4a59-b1cb-e5e3e6b67f4b","deepnote_execution_queue":[]}}